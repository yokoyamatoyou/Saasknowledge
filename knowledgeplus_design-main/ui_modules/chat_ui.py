import streamlit as st
from config import DEFAULT_KB_NAME, HYBRID_BM25_WEIGHT, HYBRID_VECTOR_WEIGHT
from knowledge_gpt_app.app import search_multiple_knowledge_bases
from shared.chat_controller import ChatController
from shared.chat_history_utils import append_message, update_title
from shared.openai_utils import get_openai_client
from shared.prompt_advisor import generate_prompt_advice
from shared.search_engine import HybridSearchEngine
from shared.upload_utils import BASE_KNOWLEDGE_DIR


def render_chat_mode(safe_generate_gpt_response):
    """Render the chat interface."""
    st.subheader("chatGPT")
    # Display current conversation title underneath the header
    st.markdown(f"### {st.session_state.get('gpt_conversation_title', 'æ–°ã—ã„ä¼šè©±')}")
    use_kb = st.session_state.get("use_knowledge_search", True)

    # Use configured search weights without showing the slider
    vec_weight = HYBRID_VECTOR_WEIGHT
    bm25_weight = HYBRID_BM25_WEIGHT

    chat_container = st.container(height=700)
    with chat_container:
        for msg in st.session_state["chat_history"]:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

    user_msg = st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡")
    if user_msg:
        st.session_state["chat_history"].append({"role": "user", "content": user_msg})
        append_message(st.session_state.current_chat_id, "user", user_msg)

        if st.session_state.get("prompt_advice"):
            client = get_openai_client()
            if client:
                advice_text = generate_prompt_advice(user_msg, client=client)
                if advice_text:
                    st.info(f"ğŸ’¡ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¢ãƒ‰ãƒã‚¤ã‚¹:\n{advice_text}")
                    st.session_state["chat_history"].append(
                        {"role": "info", "content": advice_text}
                    )
                    # append_message(st.session_state.current_chat_id, "info", advice_text)
                    append_message(
                        st.session_state.current_chat_id, "info", advice_text
                    )

        context = ""
        if use_kb:
            if "chat_controller" not in st.session_state or not isinstance(
                st.session_state.chat_controller, ChatController
            ):
                try:
                    engine = HybridSearchEngine(
                        str(BASE_KNOWLEDGE_DIR / DEFAULT_KB_NAME)
                    )
                    st.session_state.chat_controller = ChatController(engine)
                except Exception as e:
                    st.error(f"ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                    st.session_state.chat_controller = None

            if st.session_state.chat_controller:
                results, _ = search_multiple_knowledge_bases(
                    user_msg,
                    [DEFAULT_KB_NAME],
                    vector_weight=vec_weight,
                    bm25_weight=bm25_weight,
                )
                context = "\n".join(r.get("text", "") for r in results[:3])
                if not context:
                    st.info(
                        "ãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢ã§é–¢é€£æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚AIã®ä¸€èˆ¬çš„ãªçŸ¥è­˜ã§å›ç­”ã—ã¾ã™ã€‚"
                    )
            else:
                st.warning(
                    "ãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢ãŒç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã‚‹ã‹ã€ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ãŸãŸã‚ã€æ¤œç´¢ã¯è¡Œã‚ã‚Œã¾ã›ã‚“ã€‚"
                )

        client = get_openai_client()
        if client:
            prompt = (
                f"æ¬¡ã®æƒ…å ±ã‚’å‚è€ƒã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„:\n{context}\n\nè³ªå•:{user_msg}"
                if use_kb and context
                else user_msg
            )
            chat_temp = (
                0.2 if use_kb else float(st.session_state.get("temperature", 0.7))
            )
            chat_persona = st.session_state.get("persona", "default")

            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                full_response = ""
                gen = safe_generate_gpt_response(
                    prompt,
                    conversation_history=[
                        {"role": m["role"], "content": m["content"]}
                        for m in st.session_state["chat_history"][:-1]
                        if m["role"] in ("user", "assistant")
                    ],
                    persona=chat_persona,
                    temperature=chat_temp,
                    response_length="æ™®é€š",
                    client=client,
                )
                if gen:
                    for chunk in gen:
                        full_response += chunk
                        message_placeholder.markdown(full_response + "â–Œ")
                message_placeholder.markdown(full_response)
            answer = full_response
        else:
            answer = "OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        st.session_state["chat_history"].append(
            {"role": "assistant", "content": answer}
        )
        append_message(st.session_state.current_chat_id, "assistant", answer)

        if (
            not st.session_state.get("title_generated")
            and len(st.session_state.chat_history) >= 2
            and client
        ):
            current_history_for_title_gen = [
                m
                for m in st.session_state.chat_history
                if m["role"] in ["user", "assistant"]
            ]
            if current_history_for_title_gen:
                try:
                    if (
                        "chat_controller" in st.session_state
                        and st.session_state.chat_controller
                    ):
                        new_title_val = st.session_state.chat_controller.generate_conversation_title(
                            current_history_for_title_gen, client
                        )
                        st.session_state.gpt_conversation_title = new_title_val
                        update_title(st.session_state.current_chat_id, new_title_val)
                        for h in st.session_state.chat_histories:
                            if h["id"] == st.session_state.current_chat_id:
                                h["title"] = new_title_val
                                break
                        st.session_state.title_generated = True
                except Exception as e:
                    st.error(f"ä¼šè©±ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        st.rerun()
