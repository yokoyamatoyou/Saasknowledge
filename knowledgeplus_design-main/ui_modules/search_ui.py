import streamlit as st
from config import HYBRID_BM25_WEIGHT, HYBRID_VECTOR_WEIGHT
from knowledge_gpt_app.app import list_knowledge_bases, search_multiple_knowledge_bases
from shared import feedback_store
from shared.openai_utils import get_openai_client
from shared.zero_hit_logger import log_zero_hit_query
from ui_modules.document_card import render_document_card


def render_result_with_feedback(doc):
    """Render a search result and capture feedback from the user."""
    render_document_card(doc)
    chunk_id = str(
        doc.get("id")
        or doc.get("metadata", {}).get("id")
        or doc.get("metadata", {}).get("chunk_id", "")
    )
    if not chunk_id:
        return
    col_good, col_bad, _ = st.columns([0.15, 0.15, 0.7])
    if col_good.button("å½¹ã«ç«‹ã£ãŸ", key=f"useful_{chunk_id}"):
        feedback_store.record_feedback(chunk_id, 1)
        st.toast("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
    if col_bad.button("å½¹ã«ç«‹ãŸãªã‹ã£ãŸ", key=f"not_useful_{chunk_id}"):
        feedback_store.record_feedback(chunk_id, -1)
        st.toast("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä¿å­˜ã—ã¾ã—ãŸ")


def render_search_mode(safe_generate_gpt_response):
    """Refactored search interface with a clean layout and simplified controls."""
    st.subheader("ãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢")

    sidebar = st.sidebar
    if hasattr(sidebar, "checkbox"):
        if "filter_latest" not in st.session_state:
            st.session_state["filter_latest"] = False
        if "filter_company_rules" not in st.session_state:
            st.session_state["filter_company_rules"] = False
        with sidebar.expander("æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼", expanded=False):
            st.session_state["filter_latest"] = st.checkbox(
                "æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ã¿", value=st.session_state["filter_latest"]
            )
            st.session_state["filter_company_rules"] = st.checkbox(
                "ä¼šç¤¾è¦å®šã®ã¿", value=st.session_state["filter_company_rules"]
            )

    # Apply custom CSS for buttons
    st.markdown(
        """
    <style>
        div.stButton > button[kind="primary"] {
            background-color: #007bff;
            color: white;
            font-size: 16px;
            font-weight: bold;
            border: none;
            border-radius: 8px;
            padding: 12px 24px;
            width: 100%;
        }
        div.stButton > button[kind="primary"]:hover {
            background-color: #0056b3;
            color: white;
        }
        div.stButton > button[kind="secondary"] {
            background-color: #6c757d;
            color: white;
            font-size: 16px;
            font-weight: bold;
            border: none;
            border-radius: 8px;
            padding: 12px 24px;
            width: 100%;
        }
        div.stButton > button[kind="secondary"]:hover {
            background-color: #5a6268;
            color: white;
        }
    </style>
    """,
        unsafe_allow_html=True,
    )

    # Main search input
    query = st.text_input(
        "main_search_box",
        placeholder="ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢ã€ã¾ãŸã¯AIã¸ã®è³ªå•ã‚’å…¥åŠ›...",
        label_visibility="collapsed",
    )

    # Create two columns for the buttons
    col1, col2 = st.columns(2)

    # "Execute" button
    if col1.button(
        "å®Ÿè¡Œ",
        type="primary",
        help="å…¥åŠ›ã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’æ¤œç´¢ã—ã¾ã™ã€‚",
    ):
        st.session_state["search_executed"] = True
        try:
            kb_names = [kb["name"] for kb in list_knowledge_bases()]
            if kb_names:
                results, _ = search_multiple_knowledge_bases(
                    query,
                    kb_names,
                    vector_weight=HYBRID_VECTOR_WEIGHT,
                    bm25_weight=HYBRID_BM25_WEIGHT,
                )
                if st.session_state.get("filter_latest"):
                    results = [
                        r
                        for r in results
                        if not r.get("metadata", {})
                        .get("version_info", {})
                        .get("superseded_by")
                    ]
                if st.session_state.get("filter_company_rules"):
                    results = [
                        r
                        for r in results
                        if r.get("metadata", {})
                        .get("hierarchy_info", {})
                        .get("approval_level")
                        == "company"
                    ]
                st.session_state["results"] = results
                if not results:
                    log_zero_hit_query(query)
            else:
                st.session_state["results"] = []
                st.warning("æ¤œç´¢å¯èƒ½ãªãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        except Exception as e:
            st.error(f"æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.session_state["results"] = []

        st.session_state["last_query"] = query

    # "Reset" button
    if col2.button(
        "ãƒªã‚»ãƒƒãƒˆ",
        type="secondary",
        help="æ¤œç´¢ãƒœãƒƒã‚¯ã‚¹ã¨çµæœã‚’ã‚¯ãƒªã‚¢ã—ã¾ã™ã€‚",
    ):
        st.session_state["search_executed"] = False
        st.session_state["results"] = []
        st.session_state["last_query"] = ""
        st.rerun()

    if st.session_state.get("search_executed"):
        st.markdown("\n---")
        tabs = st.tabs(["AIã«ã‚ˆã‚‹è¦ç´„", "é–¢é€£ãƒŠãƒ¬ãƒƒã‚¸ä¸€è¦§"])
        with tabs[0]:
            results = st.session_state.get("results", [])
            if results:
                client = get_openai_client()
                if client:
                    context = "\n".join(r.get("text", "") for r in results[:3])
                    prompt = f"æ¬¡ã®æƒ…å ±ã‹ã‚‰è³ªå•ã€{st.session_state.get('last_query','')}ã€ã¸ã®è¦ç´„å›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„:\n{context}"
                    st.write("AIãŒè¦ç´„ã‚’ç”Ÿæˆä¸­...")
                    summary_placeholder = st.empty()
                    full_summary = ""
                    gen = safe_generate_gpt_response(
                        prompt,
                        conversation_history=[],
                        persona="default",
                        temperature=0.3,
                        response_length="ç°¡æ½”",
                        client=client,
                    )
                    if gen:
                        for chunk in gen:
                            full_summary += chunk
                            summary_placeholder.markdown(full_summary + "â–Œ")
                    summary_placeholder.markdown(full_summary)
                else:
                    st.info("è¦ç´„ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            else:
                st.info("æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        with tabs[1]:
            for doc in st.session_state.get("results", []):
                render_result_with_feedback(doc)
